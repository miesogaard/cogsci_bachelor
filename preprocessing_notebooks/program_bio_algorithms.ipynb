{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BR algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "story_1 = \"Berkah swept the ground vigorously. He wanted to ensure that everything was perfect for his queen. He had stirred awake at 4, wondering if the disinfectant was too strong for her. He had run to his master's house, woken his disgruntled co-workers and borrowed an effective disinfectant with mild odour. Her food was ready too, a tasty combination of vitamins and minerals. Berkah looked up reverently as his queen stepped into her lair, her head high. Her coat sparkled with his care and her silky mane flew in the breeze. She neighed gratefully at the delicious scent of fresh grass.\"\n",
    "\n",
    "story_2 = \"On sunny mornings, still in her dressing gown, Edith would hobble from her house, dragging along a folding chair. She would sit down in her front garden and watch people leaving for work, children going to school and dog walkers heading to the park. Anyone catching her eye was offered a friendly wave. Observing comings and goings of people made her wistful for the days when she had been a busy working mother. The people being observed noticed the old woman and wished they could trade places, longing for the day they could sit in their garden on a sunny weekday morning, carefree.\"\n",
    "\n",
    "story_3 = \"Battered and bruised, the elderly woman had stumbled and was now crawling to reach her destination. She had been badly beaten but was determined. She was a survivor and somehow everyone knew she would make it. When she arrived at the pedestal, she thrust her sword in the ground and used it as a support to raise herself to a standing position. She withdrew the sword from the ground with her right hand and collected her scales with her left. She now proudly stood tall and erect as Lady Justice had finally regained her rightful position.\"\n",
    "\n",
    "story_4 = \"After an arduous trek of more than two kilometers through the bushes, big boulders, slippery slopes from overnight rain as well as posted Warning signs not to advance further, Jim finally reached the summit of the monolithic mountain, still hosting the remnants of a past fort. But it was the last hundred meters of crawling on jagged stone that made him breathless. But from the top, the beauty of nature in front made him more breathless. The blue Aegean Sea dotted with volcanic islands and two slow-moving cruise ships, matching the blue color of cloudless sky appeared surreal. He remained stunned.\"\n",
    "\n",
    "story_5 = \"They crossed paths at a downtown club in 1984. When the material girl in the shocking-pink minidress, neon-yellow pumps, and armful of colorful bangles locked eyes with the spikey-haired rebel in the leather pants and mesh tank, love struck. They became the quintessential eighties couple, young and stylish, with a future even brighter than her clothes. These days, he hides what is left of his hair beneath a baseball hat and she has traded in her fluorescent frocks for a wardrobe of neutrals, but sometimes on Friday nights they dust off their old CDs and dance until dawn.\"\n",
    "\n",
    "\n",
    "correct_story_1 = [\"correct\", 1, 2, 2, 1]\n",
    "\n",
    "correct_story_2 = [\"correct\", 4, 3, 4, 4]\n",
    "\n",
    "correct_story_3 = [\"correct\", 1, 1, 4, 3]\n",
    "\n",
    "correct_story_4 = [\"correct\", 1, 1, 2, 3]\n",
    "\n",
    "correct_story_5 = [\"correct\", 4, 3, 2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "chosen_story = story_2\n",
    "correct_answer = correct_story_2\n",
    "story_number = 2\n",
    "\n",
    "story_questions = [\"questions\",\n",
    "             \"resources/story_\" + str(story_number) + \"_q_1.png\", \n",
    "             \"resources/story_\" + str(story_number) + \"_q_2.png\", \n",
    "             \"resources/story_\" + str(story_number) + \"_q_3.png\", \n",
    "             \"resources/story_\" + str(story_number) + \"_q_4.png\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HFLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The**y crossed paths **a**t a downtown **clu**b in 1984. **Whe**n the material **gir**l in the **shocking-pi**nk minidress, neon-yellow **pum**ps, and armful **o**f colorful bangles **lock**ed eyes with **th**e spikey-haired rebel **i**n the leather **pan**ts and mesh **tan**k, love struck. **The**y became the **quintessenti**al eighties couple, **you**ng and stylish, **wit**h a future **eve**n brighter than **he**r clothes. These **day**s, he hides **wha**t is left **o**f his hair **benea**th a baseball **ha**t and she **ha**s traded in **he**r fluorescent frocks **fo**r a wardrobe **o**f neutrals, but **sometim**es on Friday **nigh**ts they dust **of**f their old **CD**s and dance **unt**il dawn.\n"
     ]
    }
   ],
   "source": [
    "story = chosen_story\n",
    "story = story.split()\n",
    "count = 0\n",
    "hfls_story = ''\n",
    "hfls_story_python = ''\n",
    "every_third = list(range(1, len(story)+1, 3))\n",
    "next_word_cap = 'no'\n",
    "\n",
    "for i in story:\n",
    "    n = 2\n",
    "    count = count + 1\n",
    "    ending = 'none'\n",
    "    this_word_cap = 'no'\n",
    "    \n",
    "    if next_word_cap == 'yes':\n",
    "        this_word_cap = 'yes'\n",
    "    \n",
    "    next_word_cap = 'no'\n",
    "    \n",
    "    if i[-1] == '.':\n",
    "        next_word_cap = 'yes'\n",
    "        \n",
    "    if count in every_third:\n",
    "    \n",
    "        if i[-1] == ',':\n",
    "            ending = 'comma'\n",
    "            i = i[:-1]\n",
    "        elif i[-1] == '.':\n",
    "            ending = 'punct'\n",
    "            i = i[:-1]\n",
    "        \n",
    "        len_i = len(i)\n",
    "\n",
    "        if len_i == 1:\n",
    "            index_n = 1\n",
    "        elif len_i >= 2 and len_i <=4:\n",
    "            index_n = len_i-1\n",
    "        else:\n",
    "            index_n = len_i-2\n",
    "        letters = list(i)\n",
    "        letters.insert(index_n, '*')\n",
    "        letters.insert(index_n, '*')\n",
    "        letters.insert(0, '*')\n",
    "        letters.insert(0, '*')\n",
    "\n",
    "        \n",
    "        word = \"\".join(letters)\n",
    "        \n",
    "        if ending == 'comma':\n",
    "            word += ','\n",
    "        elif ending == 'punct':\n",
    "            word += '.'\n",
    "\n",
    "    else:\n",
    "        letters = list(i)\n",
    "        word = i\n",
    "        n = 0\n",
    "    \n",
    "    # Add word to story\n",
    "    hfls_story += word\n",
    "\n",
    "    # Make Python Version if cap == yes\n",
    "    if this_word_cap == 'yes' or count == 1:\n",
    "        letters.insert(n, '-')\n",
    "        word = \"\".join(letters)\n",
    "        hfls_story_python += word\n",
    "    else:\n",
    "        hfls_story_python += word\n",
    "        \n",
    "    if len(story) != count:\n",
    "        hfls_story_python += ' '\n",
    "        hfls_story += ' '\n",
    "\n",
    "\n",
    "# For each\n",
    "hfls_story_python = hfls_story_python.split()\n",
    "\n",
    "new_hfls_story = hfls_story_python\n",
    "\n",
    "#print(new_hfls_story)\n",
    "\n",
    "for i in range(0, len(hfls_story_python)):\n",
    "    new_word = \"resources/\" + hfls_story_python[i] + \".png\"\n",
    "    if \"'\" in new_word:\n",
    "        new_word = new_word.replace(\"'\", \"\")\n",
    "    new_hfls_story[i] = new_word\n",
    "\n",
    "for i in range (0, 4):\n",
    "    new_hfls_story.insert(i, \"None\")\n",
    "\n",
    "new_hfls_story.insert(0, \"words\")\n",
    "\n",
    "story_save = np.array([\"story\", \"story_\" + str(story_number)])\n",
    "condition_save = np.array([\"type_condition\", \"B\"])\n",
    "\n",
    "story_save = np.repeat(story_save, [1, len(new_hfls_story)-1], axis=0)\n",
    "condition_save = np.repeat(condition_save, [1, len(new_hfls_story)-1], axis=0)\n",
    "\n",
    "\n",
    "for r in range(1, len(new_hfls_story)):\n",
    "    story_save[r] = \"story_\" + str(story_number)\n",
    "    condition_save[r] = \"hfls\"\n",
    "\n",
    "outside_xlsx = [[], [], [], [], []]\n",
    "outside_xlsx[0] = new_hfls_story\n",
    "outside_xlsx[1] = story_questions\n",
    "outside_xlsx[2] = correct_answer\n",
    "outside_xlsx[3] = story_save\n",
    "outside_xlsx[4] = condition_save\n",
    "\n",
    "workbook = xlsxwriter.Workbook(\"story_\" + str(story_number) + \"_hfls.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "row = 0\n",
    "\n",
    "for col, data in enumerate(outside_xlsx):\n",
    "    worksheet.write_column(row, col, data)\n",
    "\n",
    "workbook.close()\n",
    "\n",
    "#df = pd.DataFrame(outside_xlsx).T\n",
    "#df.to_excel(excel_writer = \"~/story_\" + str(story_number) + \"_hfls.xlsx\")\n",
    "\n",
    "print(hfls_story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The**y crossed paths **a**t a downtown **clu**b in 1984. **Whe**n the material **gir**l in the **shocking-pi**nk minidress, neon-yellow **pum**ps, and armful **o**f colorful bangles **lock**ed eyes with **th**e spikey-haired rebel **i**n the leather **pan**ts and mesh **tan**k, love struck. **The**y became the **quintessenti**al eighties couple, **you**ng and stylish, **wit**h a future **eve**n brighter than **he**r clothes. These **day**s, he hides **wha**t is left **o**f his hair **benea**th a baseball **ha**t and she **ha**s traded in **he**r fluorescent frocks **fo**r a wardrobe **o**f neutrals, but **sometim**es on Friday **nigh**ts they dust **of**f their old **CD**s and dance **unt**il dawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = chosen_story\n",
    "story = story.split()\n",
    "count = 0\n",
    "lfls_story = ''\n",
    "lfls_story_python = ''\n",
    "every_third = list(range(1, len(story)+1, 3))\n",
    "next_word_cap = 'no'\n",
    "\n",
    "for i in story:\n",
    "    n = 2\n",
    "    count = count + 1\n",
    "    ending = 'none'\n",
    "    this_word_cap = 'no'\n",
    "    \n",
    "    if next_word_cap == 'yes':\n",
    "        this_word_cap = 'yes'\n",
    "    \n",
    "    next_word_cap = 'no'\n",
    "    \n",
    "    if i[-1] == '.':\n",
    "        next_word_cap = 'yes'\n",
    "        \n",
    "    if count in every_third:\n",
    "    \n",
    "        if i[-1] == ',':\n",
    "            ending = 'comma'\n",
    "            i = i[:-1]\n",
    "        elif i[-1] == '.':\n",
    "            ending = 'punct'\n",
    "            i = i[:-1]\n",
    "\n",
    "        len_i = len(i)\n",
    "        if len_i <= 4:\n",
    "            index_n = 1\n",
    "        elif len_i > 4 and len_i <= 9:\n",
    "            index_n = 2\n",
    "        else:\n",
    "            index_n = 3\n",
    "        letters = list(i)\n",
    "        letters.insert(index_n, '*')\n",
    "        letters.insert(index_n, '*')\n",
    "        letters.insert(0, '*')\n",
    "        letters.insert(0, '*')\n",
    "\n",
    "        \n",
    "        word = \"\".join(letters)\n",
    "        \n",
    "        if ending == 'comma':\n",
    "            word += ','\n",
    "        elif ending == 'punct':\n",
    "            word += '.' \n",
    "            \n",
    "    else:\n",
    "        letters = list(i)\n",
    "        word = i\n",
    "        n = 0\n",
    "    \n",
    "    # Add word to story\n",
    "    lfls_story += word\n",
    "\n",
    "    # Make Python Version if cap == yes\n",
    "    if this_word_cap == 'yes' or count == 1:\n",
    "        letters.insert(n, '-')\n",
    "        word = \"\".join(letters)\n",
    "        lfls_story_python += word\n",
    "    else:\n",
    "        lfls_story_python += word\n",
    "        \n",
    "    if len(story) != count:\n",
    "        lfls_story_python += ' '\n",
    "        lfls_story += ' '\n",
    "\n",
    "        \n",
    "### Converting to xlsx file ###\n",
    "\n",
    "lfls_story_python = lfls_story_python.split()\n",
    "\n",
    "new_lfls_story = lfls_story_python\n",
    "\n",
    "#print(new_hfls_story)\n",
    "\n",
    "for i in range(0, len(lfls_story_python)):\n",
    "    new_word = \"resources/\" + lfls_story_python[i] + \".png\"\n",
    "    if \"'\" in new_word:\n",
    "        new_word = new_word.replace(\"'\", \"\")\n",
    "    new_lfls_story[i] = new_word\n",
    "\n",
    "for i in range (0, 4):\n",
    "    new_lfls_story.insert(i, \"None\")\n",
    "    \n",
    "new_lfls_story.insert(0, \"words\")\n",
    "\n",
    "\n",
    "story_save = np.array([\"story\", \"story_\" + str(story_number)])\n",
    "condition_save = np.array([\"type_condition\", \"B\"])\n",
    "\n",
    "story_save = np.repeat(story_save, [1, len(new_lfls_story)-1], axis=0)\n",
    "condition_save = np.repeat(condition_save, [1, len(new_lfls_story)-1], axis=0)\n",
    "\n",
    "\n",
    "for r in range(1, len(new_lfls_story)):\n",
    "    story_save[r] = \"story_\" + str(story_number)\n",
    "    condition_save[r] = \"lfls\"\n",
    "\n",
    "outside_xlsx = [[], [], [], [], []]\n",
    "outside_xlsx[0] = new_lfls_story\n",
    "outside_xlsx[1] = story_questions\n",
    "outside_xlsx[2] = correct_answer\n",
    "outside_xlsx[3] = story_save\n",
    "outside_xlsx[4] = condition_save\n",
    "\n",
    "workbook = xlsxwriter.Workbook(\"story_\" + str(story_number) + \"_lfls.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "row = 0\n",
    "\n",
    "for col, data in enumerate(outside_xlsx):\n",
    "    worksheet.write_column(row, col, data)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HFHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**O**n **sun**ny **mornin**gs, **sti**ll **i**n **he**r **dressi**ng **gow**n, **Edi**th **wou**ld **hobb**le **fro**m **he**r **hou**se, **draggi**ng **alo**ng **a** **foldi**ng **cha**ir. **Sh**e **wou**ld **si**t **dow**n **i**n **he**r **fro**nt **gard**en **an**d **wat**ch **peop**le **leavi**ng **fo**r **wor**k, **childr**en **goi**ng **t**o **scho**ol **an**d **do**g **walke**rs **headi**ng **t**o **th**e **par**k. **Anyo**ne **catchi**ng **he**r **ey**e **wa**s **offer**ed **a** **friend**ly **wav**e. **Observi**ng **comin**gs **an**d **goin**gs **o**f **peop**le **mad**e **he**r **wistf**ul **fo**r **th**e **day**s **whe**n **sh**e **ha**d **bee**n **a** **bus**y **worki**ng **moth**er. **Th**e **peop**le **bei**ng **observ**ed **notic**ed **th**e **ol**d **wom**an **an**d **wish**ed **the**y **cou**ld **tra**de **plac**es, **longi**ng **fo**r **th**e **da**y **the**y **cou**ld **si**t **i**n **the**ir **gard**en **o**n **a** **sun**ny **weekd**ay **morni**ng, **carefr**ee.\n"
     ]
    }
   ],
   "source": [
    "# Here we place an algortihm on each story\n",
    "\n",
    "story = chosen_story\n",
    "story = story.split()\n",
    "count = 0\n",
    "hfhs_story = ''\n",
    "hfhs_story_python = ''\n",
    "every_third = list(range(1, len(story)+1, 3))\n",
    "next_word_cap = 'no'\n",
    "\n",
    "for i in story:\n",
    "    count = count + 1\n",
    "    ending = 'none'\n",
    "    this_word_cap = 'no'\n",
    "    \n",
    "    if next_word_cap == 'yes':\n",
    "        this_word_cap = 'yes'\n",
    "    \n",
    "    next_word_cap = 'no'\n",
    "    \n",
    "    # Remove comma or punctuation\n",
    "    if i[-1] == ',':\n",
    "        ending = 'comma'\n",
    "        i = i[:-1]\n",
    "    elif i[-1] == '.':\n",
    "        ending = 'punct'\n",
    "        i = i[:-1]\n",
    "        next_word_cap = 'yes'\n",
    "    \n",
    "    # Length of word\n",
    "    len_i = len(i)\n",
    "        \n",
    "    if len_i == 1:\n",
    "        index_n = 1\n",
    "    elif len_i >= 2 and len_i <=4:\n",
    "        index_n = len_i-1\n",
    "    else:\n",
    "        index_n = len_i-2\n",
    "    \n",
    "    # Make each letter an item in a list\n",
    "    letters = list(i)\n",
    "    \n",
    "    \n",
    "    # Insert inside the word\n",
    "    letters.insert(index_n, '*')\n",
    "    letters.insert(index_n, '*')\n",
    "    \n",
    "    # Insert in the beginning\n",
    "    letters.insert(0, '*')\n",
    "    letters.insert(0, '*')\n",
    "    \n",
    "    word = \"\".join(letters)\n",
    "    \n",
    "    # Add comma or punctuation again\n",
    "    if ending == 'comma':\n",
    "        word += ','\n",
    "    elif ending == 'punct':\n",
    "        word += '.'\n",
    "        \n",
    "    # Add word to story\n",
    "    hfhs_story += word\n",
    "\n",
    "    # Make Python Version if cap == yes\n",
    "    if this_word_cap == 'yes' or count == 1:\n",
    "        letters.insert(2, '-')\n",
    "        word = \"\".join(letters)\n",
    "        hfhs_story_python += word\n",
    "    else:\n",
    "        hfhs_story_python += word\n",
    "        \n",
    "        \n",
    "    if len(story) != count:\n",
    "        hfhs_story_python += ' '\n",
    "        hfhs_story += ' '\n",
    "        \n",
    "    \n",
    "### Converting to xlsx file ###\n",
    "\n",
    "hfhs_story_python = hfhs_story_python.split()\n",
    "\n",
    "new_hfhs_story = hfhs_story_python\n",
    "\n",
    "\n",
    "for i in range(0, len(hfhs_story_python)):\n",
    "    new_word = \"resources/\" + hfhs_story_python[i] + \".png\"\n",
    "    if \"'\" in new_word:\n",
    "        new_word = new_word.replace(\"'\", \"\")\n",
    "    new_hfhs_story[i] = new_word\n",
    "\n",
    "for i in range (0, 4):\n",
    "    new_hfhs_story.insert(i, \"None\")\n",
    "\n",
    "new_hfhs_story.insert(0, \"words\")\n",
    "\n",
    "story_save = np.array([\"story\", \"story_\" + str(story_number)])\n",
    "condition_save = np.array([\"type_condition\", \"B\"])\n",
    "\n",
    "story_save = np.repeat(story_save, [1, len(new_hfhs_story)-1], axis=0)\n",
    "condition_save = np.repeat(condition_save, [1, len(new_hfhs_story)-1], axis=0)\n",
    "\n",
    "\n",
    "for r in range(1, len(new_hfhs_story)):\n",
    "    story_save[r] = \"story_\" + str(story_number)\n",
    "    condition_save[r] = \"hfhs\"\n",
    "\n",
    "outside_xlsx = [[], [], [], [], []]\n",
    "outside_xlsx[0] = new_hfhs_story\n",
    "outside_xlsx[1] = story_questions\n",
    "outside_xlsx[2] = correct_answer\n",
    "outside_xlsx[3] = story_save\n",
    "outside_xlsx[4] = condition_save\n",
    "\n",
    "workbook = xlsxwriter.Workbook(\"story_\" + str(story_number) + \"_hfhs.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "row = 0\n",
    "\n",
    "for col, data in enumerate(outside_xlsx):\n",
    "    worksheet.write_column(row, col, data)\n",
    "\n",
    "workbook.close()\n",
    "\n",
    "print(hfhs_story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**O**n **sun**ny **mornin**gs, **sti**ll **i**n **he**r **dressi**ng **gow**n, **Edi**th **wou**ld **hobb**le **fro**m **he**r **hou**se, **draggi**ng **alo**ng **a** **foldi**ng **cha**ir. **Sh**e **wou**ld **si**t **dow**n **i**n **he**r **fro**nt **gard**en **an**d **wat**ch **peop**le **leavi**ng **fo**r **wor**k, **childr**en **goi**ng **t**o **scho**ol **an**d **do**g **walke**rs **headi**ng **t**o **th**e **par**k. **Anyo**ne **catchi**ng **he**r **ey**e **wa**s **offer**ed **a** **friend**ly **wav**e. **Observi**ng **comin**gs **an**d **goin**gs **o**f **peop**le **mad**e **he**r **wistf**ul **fo**r **th**e **day**s **whe**n **sh**e **ha**d **bee**n **a** **bus**y **worki**ng **moth**er. **Th**e **peop**le **bei**ng **observ**ed **notic**ed **th**e **ol**d **wom**an **an**d **wish**ed **the**y **cou**ld **tra**de **plac**es, **longi**ng **fo**r **th**e **da**y **the**y **cou**ld **si**t **i**n **the**ir **gard**en **o**n **a** **sun**ny **weekd**ay **morni**ng, **carefr**ee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LFHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "story = chosen_story\n",
    "story = story.split()\n",
    "count = 0\n",
    "new_story = ''\n",
    "lfhs_story_python = ''\n",
    "every_third = list(range(1, len(story)+1, 3))\n",
    "next_word_cap = 'no'\n",
    "\n",
    "\n",
    "for i in story:\n",
    "    count = count + 1\n",
    "    ending = 'none'\n",
    "    this_word_cap = 'no'\n",
    "    \n",
    "    if next_word_cap == 'yes':\n",
    "        this_word_cap = 'yes'\n",
    "    \n",
    "    next_word_cap = 'no'\n",
    "    \n",
    "    if i[-1] == ',':\n",
    "        ending = 'comma'\n",
    "        i = i[:-1]\n",
    "    elif i[-1] == '.':\n",
    "        ending = 'punct'\n",
    "        i = i[:-1]\n",
    "        next_word_cap = 'yes'\n",
    "        \n",
    "    len_i = len(i)\n",
    "        \n",
    "    if len_i <= 4:\n",
    "        index_n = 1\n",
    "    elif len_i > 4 and len_i <= 9:\n",
    "        index_n = 2\n",
    "    else:\n",
    "        index_n = 3\n",
    "    letters = list(i)\n",
    "    letters.insert(index_n, '*')\n",
    "    letters.insert(index_n, '*')\n",
    "    letters.insert(0, '*')\n",
    "    letters.insert(0, '*')\n",
    "    word = \"\".join(letters)\n",
    "        \n",
    "    if ending == 'comma':\n",
    "        word += ','\n",
    "    elif ending == 'punct':\n",
    "        word += '.'\n",
    "            \n",
    "    # Add word to story\n",
    "    new_story += word\n",
    "\n",
    "    # Make Python Version if cap == yes\n",
    "    if this_word_cap == 'yes' or count == 1:\n",
    "        letters.insert(2, '-')\n",
    "        word = \"\".join(letters)\n",
    "        lfhs_story_python += word\n",
    "    else:\n",
    "        lfhs_story_python += word\n",
    "        \n",
    "        \n",
    "    if len(story) != count:\n",
    "        lfhs_story_python += ' '\n",
    "        new_story += ' '\n",
    "        \n",
    "### Converting to xlsx file ###\n",
    "\n",
    "lfhs_story_python = lfhs_story_python.split()\n",
    "\n",
    "new_lfhs_story = lfhs_story_python\n",
    "\n",
    "#print(new_hfls_story)\n",
    "\n",
    "for i in range(0, len(lfhs_story_python)):\n",
    "    new_word = \"resources/\" + lfhs_story_python[i] + \".png\"\n",
    "    if \"'\" in new_word:\n",
    "        new_word = new_word.replace(\"'\", \"\")\n",
    "    new_lfhs_story[i] = new_word\n",
    "\n",
    "for i in range (0, 4):\n",
    "    new_lfhs_story.insert(i, \"None\")\n",
    "    \n",
    "new_lfhs_story.insert(0, \"words\")\n",
    "\n",
    "story_save = np.array([\"story\", \"story_\" + str(story_number)])\n",
    "condition_save = np.array([\"type_condition\", \"B\"])\n",
    "\n",
    "story_save = np.repeat(story_save, [1, len(new_lfhs_story)-1], axis=0)\n",
    "condition_save = np.repeat(condition_save, [1, len(new_lfhs_story)-1], axis=0)\n",
    "\n",
    "\n",
    "for r in range(1, len(new_lfhs_story)):\n",
    "    story_save[r] = \"story_\" + str(story_number)\n",
    "    condition_save[r] = \"lfhs\"\n",
    "\n",
    "outside_xlsx = [[], [], [], [], []]\n",
    "outside_xlsx[0] = new_lfhs_story\n",
    "outside_xlsx[1] = story_questions\n",
    "outside_xlsx[2] = correct_answer\n",
    "outside_xlsx[3] = story_save\n",
    "outside_xlsx[4] = condition_save\n",
    "\n",
    "\n",
    "workbook = xlsxwriter.Workbook(\"story_\" + str(story_number) + \"_lfhs.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "row = 0\n",
    "\n",
    "for col, data in enumerate(outside_xlsx):\n",
    "    worksheet.write_column(row, col, data)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = chosen_story\n",
    "story = story.split()\n",
    "count = 0\n",
    "control_story = ''\n",
    "control_story_python = ''\n",
    "every_third = list(range(1, len(story)+1, 3))\n",
    "next_word_cap = 'no'\n",
    "\n",
    "for i in story:\n",
    "    count = count + 1\n",
    "    ending = 'none'\n",
    "    this_word_cap = 'no'\n",
    "    word = i\n",
    "    \n",
    "    if next_word_cap == 'yes':\n",
    "        this_word_cap = 'yes'\n",
    "    \n",
    "    next_word_cap = 'no'\n",
    "    \n",
    "    # Remove comma or punctuation\n",
    "    if i[-1] == ',':\n",
    "        ending = 'comma'\n",
    "    elif i[-1] == '.':\n",
    "        ending = 'punct'\n",
    "        next_word_cap = 'yes'\n",
    "\n",
    "        \n",
    "    # Add word to story\n",
    "    control_story += word\n",
    "\n",
    "    # Make Python Version if cap == yes\n",
    "    if this_word_cap == 'yes' or count == 1:\n",
    "        control_story_python = control_story_python + '-' + word\n",
    "    else:\n",
    "        control_story_python += word\n",
    "        \n",
    "        \n",
    "    if len(story) != count:\n",
    "        control_story_python += ' '\n",
    "        control_story += ' '\n",
    "\n",
    "### Converting to xlsx file ###\n",
    "\n",
    "control_story_python = control_story_python.split()\n",
    "\n",
    "new_control_story = control_story_python\n",
    "\n",
    "#print(new_hfls_story)\n",
    "\n",
    "for i in range(0, len(control_story_python)):\n",
    "    new_word = \"resources/\" + control_story_python[i] + \".png\"\n",
    "    if \"'\" in new_word:\n",
    "        new_word = new_word.replace(\"'\", \"\")\n",
    "    new_control_story[i] = new_word\n",
    "\n",
    "for i in range (0, 4):\n",
    "    new_control_story.insert(i, \"None\")\n",
    "    \n",
    "new_control_story.insert(0, \"words\")\n",
    "\n",
    "story_save = np.array([\"story\", \"story_\" + str(story_number)])\n",
    "condition_save = np.array([\"type_condition\", \"B\"])\n",
    "\n",
    "story_save = np.repeat(story_save, [1, len(new_control_story)-1], axis=0)\n",
    "condition_save = np.repeat(condition_save, [1, len(new_control_story)-1], axis=0)\n",
    "\n",
    "\n",
    "for r in range(1, len(new_hfhs_story)):\n",
    "    story_save[r] = \"story_\" + str(story_number)\n",
    "    condition_save[r] = \"control\"\n",
    "\n",
    "outside_xlsx = [[], [], [], [], []]\n",
    "outside_xlsx[0] = new_control_story\n",
    "outside_xlsx[1] = story_questions\n",
    "outside_xlsx[2] = correct_answer\n",
    "outside_xlsx[3] = story_save\n",
    "outside_xlsx[4] = condition_save\n",
    "\n",
    "workbook = xlsxwriter.Workbook(\"story_\" + str(story_number) + \"_control.xlsx\")\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "row = 0\n",
    "\n",
    "for col, data in enumerate(outside_xlsx):\n",
    "    worksheet.write_column(row, col, data)\n",
    "\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding all unique words \n",
    "## (so I don't have to spend time on remembering duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all stories into one string\n",
    "all_stories = story_1 + ' ' + story_2 + ' ' + story_3 + ' ' + story_4 + ' ' + story_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Berk**ah **swe**pt **th**e **grou**nd **vigorous**ly. **H**e **want**ed **t**o **ensu**re **tha**t **everythi**ng **wa**s **perfe**ct **fo**r **hi**s **que**en. **H**e **ha**d **stirr**ed **awa**ke **a**t **4**, **wonderi**ng **i**f **th**e **disinfecta**nt **wa**s **to**o **stro**ng **fo**r **he**r. **H**e **ha**d **ru**n **t**o **hi**s **master**'s **hou**se, **wok**en **hi**s **disgruntl**ed **co-worke**rs **an**d **borrow**ed **a**n **effecti**ve **disinfecta**nt **wit**h **mil**d **odo**ur. **He**r **foo**d **wa**s **rea**dy **to**o, **a** **tas**ty **combinati**on **o**f **vitami**ns **an**d **minera**ls. **Berk**ah **look**ed **u**p **reverent**ly **a**s **hi**s **que**en **stepp**ed **int**o **he**r **lai**r, **he**r **hea**d **hig**h. **He**r **coa**t **sparkl**ed **wit**h **hi**s **car**e **an**d **he**r **sil**ky **man**e **fle**w **i**n **th**e **bree**ze. **Sh**e **neigh**ed **grateful**ly **a**t **th**e **delicio**us **sce**nt **o**f **fre**sh **gra**ss. **O**n **sun**ny **mornin**gs, **sti**ll **i**n **he**r **dressi**ng **gow**n, **Edi**th **wou**ld **hobb**le **fro**m **he**r **hou**se, **draggi**ng **alo**ng **a** **foldi**ng **cha**ir. **Sh**e **wou**ld **si**t **dow**n **i**n **he**r **fro**nt **gard**en **an**d **wat**ch **peop**le **leavi**ng **fo**r **wor**k, **childr**en **goi**ng **t**o **scho**ol **an**d **do**g **walke**rs **headi**ng **t**o **th**e **par**k. **Anyo**ne **catchi**ng **he**r **ey**e **wa**s **offer**ed **a** **friend**ly **wav**e. **Observi**ng **comin**gs **an**d **goin**gs **o**f **peop**le **mad**e **he**r **wistf**ul **fo**r **th**e **day**s **whe**n **sh**e **ha**d **bee**n **a** **bus**y **worki**ng **moth**er. **Th**e **peop**le **bei**ng **observ**ed **notic**ed **th**e **ol**d **wom**an **an**d **wish**ed **the**y **cou**ld **tra**de **plac**es, **longi**ng **fo**r **th**e **da**y **the**y **cou**ld **si**t **i**n **the**ir **gard**en **o**n **a** **sun**ny **weekd**ay **morni**ng, **carefr**ee. **Batter**ed **an**d **bruis**ed, **th**e **elder**ly **wom**an **ha**d **stumbl**ed **an**d **wa**s **no**w **crawli**ng **t**o **rea**ch **he**r **destinati**on. **Sh**e **ha**d **bee**n **bad**ly **beat**en **bu**t **wa**s **determin**ed. **Sh**e **wa**s **a** **surviv**or **an**d **someh**ow **everyo**ne **kne**w **sh**e **wou**ld **mak**e **i**t. **Whe**n **sh**e **arriv**ed **a**t **th**e **pedest**al, **sh**e **thru**st **he**r **swo**rd **i**n **th**e **grou**nd **an**d **use**d **i**t **a**s **a** **suppo**rt **t**o **rai**se **herse**lf **t**o **a** **standi**ng **positi**on. **Sh**e **withdr**ew **th**e **swo**rd **fro**m **th**e **grou**nd **wit**h **he**r **rig**ht **han**d **an**d **collect**ed **he**r **scal**es **wit**h **he**r **lef**t. **Sh**e **no**w **proud**ly **sto**od **tal**l **an**d **ere**ct **a**s **Lad**y **Justi**ce **ha**d **final**ly **regain**ed **he**r **rightf**ul **positi**on. **Aft**er **a**n **arduo**us **tre**k **o**f **mor**e **tha**n **tw**o **kilomete**rs **throu**gh **th**e **bush**es, **bi**g **boulde**rs, **slippe**ry **slop**es **fro**m **overnig**ht **rai**n **a**s **wel**l **a**s **post**ed **Warni**ng **sig**ns **no**t **t**o **advan**ce **furth**er, **Ji**m **final**ly **reach**ed **th**e **summ**it **o**f **th**e **monolith**ic **mounta**in, **sti**ll **hosti**ng **th**e **remnan**ts **o**f **a** **pas**t **for**t. **Bu**t **i**t **wa**s **th**e **las**t **hundr**ed **mete**rs **o**f **crawli**ng **o**n **jagg**ed **sto**ne **tha**t **mad**e **hi**m **breathle**ss. **Bu**t **fro**m **th**e **to**p, **th**e **beau**ty **o**f **natu**re **i**n **fro**nt **mad**e **hi**m **mor**e **breathle**ss. **Th**e **blu**e **Aege**an **Se**a **dott**ed **wit**h **volcan**ic **islan**ds **an**d **tw**o **slow-movi**ng **crui**se **shi**ps, **matchi**ng **th**e **blu**e **col**or **o**f **cloudle**ss **sk**y **appear**ed **surre**al. **H**e **remain**ed **stunn**ed. **The**y **cross**ed **pat**hs **a**t **a** **downto**wn **clu**b **i**n **198**4. **Whe**n **th**e **materi**al **gir**l **i**n **th**e **shocking-pi**nk **minidre**ss, **neon-yell**ow **pum**ps, **an**d **armf**ul **o**f **colorf**ul **bangl**es **lock**ed **eye**s **wit**h **th**e **spikey-hair**ed **reb**el **i**n **th**e **leath**er **pan**ts **an**d **mes**h **tan**k, **lov**e **stru**ck. **The**y **beca**me **th**e **quintessenti**al **eighti**es **coup**le, **you**ng **an**d **styli**sh, **wit**h **a** **futu**re **eve**n **bright**er **tha**n **he**r **cloth**es. **The**se **day**s, **h**e **hid**es **wha**t **i**s **lef**t **o**f **hi**s **hai**r **benea**th **a** **baseba**ll **ha**t **an**d **sh**e **ha**s **trad**ed **i**n **he**r **fluoresce**nt **froc**ks **fo**r **a** **wardro**be **o**f **neutra**ls, **bu**t **sometim**es **o**n **Frid**ay **nigh**ts **the**y **dus**t **of**f **the**ir **ol**d **CD**s **an**d **dan**ce **unt**il **daw**n.\n"
     ]
    }
   ],
   "source": [
    "# Here we place an algortihm on each story (both fixation conditions with high saccades)\n",
    "\n",
    "story = all_stories\n",
    "story = story.split()\n",
    "count = 0\n",
    "all_hfhs_story = ''\n",
    "all_hfhs_story_python = ''\n",
    "every_third = list(range(1, len(story)+1, 3))\n",
    "next_word_cap = 'no'\n",
    "\n",
    "for i in story:\n",
    "    count = count + 1\n",
    "    ending = 'none'\n",
    "    this_word_cap = 'no'\n",
    "    \n",
    "    if next_word_cap == 'yes':\n",
    "        this_word_cap = 'yes'\n",
    "    \n",
    "    next_word_cap = 'no'\n",
    "    \n",
    "    # Remove comma or punctuation\n",
    "    if i[-1] == ',':\n",
    "        ending = 'comma'\n",
    "        i = i[:-1]\n",
    "    elif i[-1] == '.':\n",
    "        ending = 'punct'\n",
    "        i = i[:-1]\n",
    "        next_word_cap = 'yes'\n",
    "    \n",
    "    # Length of word\n",
    "    len_i = len(i)\n",
    "        \n",
    "    if len_i == 1:\n",
    "        index_n = 1\n",
    "    elif len_i >= 2 and len_i <=4:\n",
    "        index_n = len_i-1\n",
    "    else:\n",
    "        index_n = len_i-2\n",
    "    \n",
    "    # Make each letter an item in a list\n",
    "    letters = list(i)\n",
    "    \n",
    "    \n",
    "    # Insert inside the word\n",
    "    letters.insert(index_n, '*')\n",
    "    letters.insert(index_n, '*')\n",
    "    \n",
    "    # Insert in the beginning\n",
    "    letters.insert(0, '*')\n",
    "    letters.insert(0, '*')\n",
    "    \n",
    "    word = \"\".join(letters)\n",
    "    \n",
    "    # Add comma or punctuation again\n",
    "    if ending == 'comma':\n",
    "        word += ','\n",
    "    elif ending == 'punct':\n",
    "        word += '.'\n",
    "        \n",
    "    # Add word to story\n",
    "    all_hfhs_story += word\n",
    "\n",
    "    # Make Python Version if cap == yes\n",
    "    if this_word_cap == 'yes' or count == 1:\n",
    "        letters.insert(2, '-')\n",
    "        word = \"\".join(letters)\n",
    "        all_hfhs_story_python += word\n",
    "    else:\n",
    "        all_hfhs_story_python += word\n",
    "        \n",
    "        \n",
    "    if len(story) != count:\n",
    "        all_hfhs_story_python += ' '\n",
    "        all_hfhs_story += ' '\n",
    "        \n",
    "    \n",
    "print(all_hfhs_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Be**rkah **sw**ept **t**he **gr**ound **vig**orously. **H**e **wa**nted **t**o **en**sure **t**hat **eve**rything **w**as **pe**rfect **f**or **h**is **qu**een. **H**e **h**ad **st**irred **aw**ake **a**t **4**, **wo**ndering **i**f **t**he **dis**infectant **w**as **t**oo **st**rong **f**or **h**er. **H**e **h**ad **r**un **t**o **h**is **ma**ster's **ho**use, **wo**ken **h**is **dis**gruntled **co-**workers **a**nd **bo**rrowed **a**n **ef**fective **dis**infectant **w**ith **m**ild **od**our. **H**er **f**ood **w**as **re**ady **t**oo, **a** **ta**sty **com**bination **o**f **vi**tamins **a**nd **mi**nerals. **Be**rkah **lo**oked **u**p **rev**erently **a**s **h**is **qu**een **st**epped **i**nto **h**er **l**air, **h**er **h**ead **h**igh. **H**er **c**oat **sp**arkled **w**ith **h**is **c**are **a**nd **h**er **si**lky **m**ane **f**lew **i**n **t**he **br**eeze. **S**he **ne**ighed **gra**tefully **a**t **t**he **de**licious **sc**ent **o**f **fr**esh **gr**ass. **O**n **su**nny **mo**rnings, **st**ill **i**n **h**er **dr**essing **g**own, **Ed**ith **wo**uld **ho**bble **f**rom **h**er **ho**use, **dr**agging **al**ong **a** **fo**lding **ch**air. **S**he **wo**uld **s**it **d**own **i**n **h**er **fr**ont **ga**rden **a**nd **wa**tch **pe**ople **le**aving **f**or **w**ork, **ch**ildren **go**ing **t**o **sc**hool **a**nd **d**og **wa**lkers **he**ading **t**o **t**he **p**ark. **An**yone **ca**tching **h**er **e**ye **w**as **of**fered **a** **fr**iendly **w**ave. **Ob**serving **co**mings **a**nd **go**ings **o**f **pe**ople **m**ade **h**er **wi**stful **f**or **t**he **d**ays **w**hen **s**he **h**ad **b**een **a** **b**usy **wo**rking **mo**ther. **T**he **pe**ople **be**ing **ob**served **no**ticed **t**he **o**ld **wo**man **a**nd **wi**shed **t**hey **co**uld **tr**ade **pl**aces, **lo**nging **f**or **t**he **d**ay **t**hey **co**uld **s**it **i**n **th**eir **ga**rden **o**n **a** **su**nny **we**ekday **mo**rning, **ca**refree. **Ba**ttered **a**nd **br**uised, **t**he **el**derly **wo**man **h**ad **st**umbled **a**nd **w**as **n**ow **cr**awling **t**o **re**ach **h**er **des**tination. **S**he **h**ad **b**een **ba**dly **be**aten **b**ut **w**as **det**ermined. **S**he **w**as **a** **su**rvivor **a**nd **so**mehow **ev**eryone **k**new **s**he **wo**uld **m**ake **i**t. **W**hen **s**he **ar**rived **a**t **t**he **pe**destal, **s**he **th**rust **h**er **sw**ord **i**n **t**he **gr**ound **a**nd **u**sed **i**t **a**s **a** **su**pport **t**o **ra**ise **he**rself **t**o **a** **st**anding **po**sition. **S**he **wi**thdrew **t**he **sw**ord **f**rom **t**he **gr**ound **w**ith **h**er **ri**ght **h**and **a**nd **co**llected **h**er **sc**ales **w**ith **h**er **l**eft. **S**he **n**ow **pr**oudly **st**ood **t**all **a**nd **er**ect **a**s **L**ady **Ju**stice **h**ad **fi**nally **re**gained **h**er **ri**ghtful **po**sition. **Af**ter **a**n **ar**duous **t**rek **o**f **m**ore **t**han **t**wo **kil**ometers **th**rough **t**he **bu**shes, **b**ig **bo**ulders, **sl**ippery **sl**opes **f**rom **ov**ernight **r**ain **a**s **w**ell **a**s **po**sted **Wa**rning **si**gns **n**ot **t**o **ad**vance **fu**rther, **J**im **fi**nally **re**ached **t**he **su**mmit **o**f **t**he **mon**olithic **mo**untain, **st**ill **ho**sting **t**he **re**mnants **o**f **a** **p**ast **f**ort. **B**ut **i**t **w**as **t**he **l**ast **hu**ndred **me**ters **o**f **cr**awling **o**n **ja**gged **st**one **t**hat **m**ade **h**im **bre**athless. **B**ut **f**rom **t**he **t**op, **t**he **be**auty **o**f **na**ture **i**n **fr**ont **m**ade **h**im **m**ore **bre**athless. **T**he **b**lue **Ae**gean **S**ea **do**tted **w**ith **vo**lcanic **is**lands **a**nd **t**wo **slo**w-moving **cr**uise **sh**ips, **ma**tching **t**he **b**lue **co**lor **o**f **cl**oudless **s**ky **ap**peared **su**rreal. **H**e **re**mained **st**unned. **T**hey **cr**ossed **pa**ths **a**t **a** **do**wntown **c**lub **i**n **1**984. **W**hen **t**he **ma**terial **g**irl **i**n **t**he **sho**cking-pink **mi**nidress, **neo**n-yellow **pu**mps, **a**nd **ar**mful **o**f **co**lorful **ba**ngles **lo**cked **e**yes **w**ith **t**he **spi**key-haired **re**bel **i**n **t**he **le**ather **pa**nts **a**nd **m**esh **t**ank, **l**ove **st**ruck. **T**hey **be**came **t**he **qui**ntessential **ei**ghties **co**uple, **yo**ung **a**nd **st**ylish, **w**ith **a** **fu**ture **e**ven **br**ighter **t**han **h**er **cl**othes. **Th**ese **d**ays, **h**e **hi**des **w**hat **i**s **l**eft **o**f **h**is **h**air **be**neath **a** **ba**seball **h**at **a**nd **s**he **h**as **tr**aded **i**n **h**er **flu**orescent **fr**ocks **f**or **a** **wa**rdrobe **o**f **ne**utrals, **b**ut **so**metimes **o**n **Fr**iday **ni**ghts **t**hey **d**ust **o**ff **th**eir **o**ld **C**Ds **a**nd **da**nce **un**til **d**awn.\n"
     ]
    }
   ],
   "source": [
    "story = all_stories\n",
    "story = story.split()\n",
    "count = 0\n",
    "all_lfhs_story = ''\n",
    "all_lfhs_story_python = ''\n",
    "every_third = list(range(1, len(story)+1, 3))\n",
    "next_word_cap = 'no'\n",
    "\n",
    "\n",
    "for i in story:\n",
    "    count = count + 1\n",
    "    ending = 'none'\n",
    "    this_word_cap = 'no'\n",
    "    \n",
    "    if next_word_cap == 'yes':\n",
    "        this_word_cap = 'yes'\n",
    "    \n",
    "    next_word_cap = 'no'\n",
    "    \n",
    "    if i[-1] == ',':\n",
    "        ending = 'comma'\n",
    "        i = i[:-1]\n",
    "    elif i[-1] == '.':\n",
    "        ending = 'punct'\n",
    "        i = i[:-1]\n",
    "        next_word_cap = 'yes'\n",
    "        \n",
    "    len_i = len(i)\n",
    "        \n",
    "    if len_i <= 4:\n",
    "        index_n = 1\n",
    "    elif len_i > 4 and len_i <= 9:\n",
    "        index_n = 2\n",
    "    else:\n",
    "        index_n = 3\n",
    "    letters = list(i)\n",
    "    letters.insert(index_n, '*')\n",
    "    letters.insert(index_n, '*')\n",
    "    letters.insert(0, '*')\n",
    "    letters.insert(0, '*')\n",
    "    word = \"\".join(letters)\n",
    "        \n",
    "    if ending == 'comma':\n",
    "        word += ','\n",
    "    elif ending == 'punct':\n",
    "        word += '.'\n",
    "            \n",
    "    # Add word to story\n",
    "    all_lfhs_story += word\n",
    "\n",
    "    # Make Python Version if cap == yes\n",
    "    if this_word_cap == 'yes' or count == 1:\n",
    "        letters.insert(2, '-')\n",
    "        word = \"\".join(letters)\n",
    "        all_lfhs_story_python += word\n",
    "    else:\n",
    "        all_lfhs_story_python += word\n",
    "        \n",
    "        \n",
    "    if len(story) != count:\n",
    "        all_lfhs_story_python += ' '\n",
    "        all_lfhs_story += ' '\n",
    "        \n",
    "print(all_lfhs_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berkah swept the ground vigorously. He wanted to ensure that everything was perfect for his queen. He had stirred awake at 4, wondering if the disinfectant was too strong for her. He had run to his master's house, woken his disgruntled co-workers and borrowed an effective disinfectant with mild odour. Her food was ready too, a tasty combination of vitamins and minerals. Berkah looked up reverently as his queen stepped into her lair, her head high. Her coat sparkled with his care and her silky mane flew in the breeze. She neighed gratefully at the delicious scent of fresh grass. On sunny mornings, still in her dressing gown, Edith would hobble from her house, dragging along a folding chair. She would sit down in her front garden and watch people leaving for work, children going to school and dog walkers heading to the park. Anyone catching her eye was offered a friendly wave. Observing comings and goings of people made her wistful for the days when she had been a busy working mother. The people being observed noticed the old woman and wished they could trade places, longing for the day they could sit in their garden on a sunny weekday morning, carefree. Battered and bruised, the elderly woman had stumbled and was now crawling to reach her destination. She had been badly beaten but was determined. She was a survivor and somehow everyone knew she would make it. When she arrived at the pedestal, she thrust her sword in the ground and used it as a support to raise herself to a standing position. She withdrew the sword from the ground with her right hand and collected her scales with her left. She now proudly stood tall and erect as Lady Justice had finally regained her rightful position. After an arduous trek of more than two kilometers through the bushes, big boulders, slippery slopes from overnight rain as well as posted Warning signs not to advance further, Jim finally reached the summit of the monolithic mountain, still hosting the remnants of a past fort. But it was the last hundred meters of crawling on jagged stone that made him breathless. But from the top, the beauty of nature in front made him more breathless. The blue Aegean Sea dotted with volcanic islands and two slow-moving cruise ships, matching the blue color of cloudless sky appeared surreal. He remained stunned. They crossed paths at a downtown club in 1984. When the material girl in the shocking-pink minidress, neon-yellow pumps, and armful of colorful bangles locked eyes with the spikey-haired rebel in the leather pants and mesh tank, love struck. They became the quintessential eighties couple, young and stylish, with a future even brighter than her clothes. These days, he hides what is left of his hair beneath a baseball hat and she has traded in her fluorescent frocks for a wardrobe of neutrals, but sometimes on Friday nights they dust off their old CDs and dance until dawn.\n"
     ]
    }
   ],
   "source": [
    "story = all_stories\n",
    "story = story.split()\n",
    "count = 0\n",
    "all_control_story = ''\n",
    "all_control_story_python = ''\n",
    "every_third = list(range(1, len(story)+1, 3))\n",
    "next_word_cap = 'no'\n",
    "\n",
    "for i in story:\n",
    "    count = count + 1\n",
    "    ending = 'none'\n",
    "    this_word_cap = 'no'\n",
    "    word = i\n",
    "    \n",
    "    if next_word_cap == 'yes':\n",
    "        this_word_cap = 'yes'\n",
    "    \n",
    "    next_word_cap = 'no'\n",
    "    \n",
    "    if i[-1] == ',':\n",
    "        ending = 'comma'\n",
    "    elif i[-1] == '.':\n",
    "        ending = 'punct'\n",
    "        next_word_cap = 'yes'\n",
    "\n",
    "    # Add word to story\n",
    "    all_control_story += word\n",
    "\n",
    "    # Make Python Version if cap == yes\n",
    "    if this_word_cap == 'yes' or count == 1:\n",
    "        all_control_story_python = all_control_story_python + '-' + word\n",
    "    else:\n",
    "        all_control_story_python += word\n",
    "        \n",
    "    if len(story) != count:\n",
    "        all_control_story_python += ' '\n",
    "        all_control_story += ' '\n",
    "\n",
    "print(all_control_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Berk**ah **swe**pt **th**e **grou**nd **vigorous**ly. **H**e **want**ed **t**o **ensu**re **tha**t **everythi**ng **wa**s **perfe**ct **fo**r **hi**s **que**en. **ha**d **stirr**ed **awa**ke **a**t **4**, **wonderi**ng **i**f **disinfecta**nt **to**o **stro**ng **he**r. **ru**n **master**'s **hou**se, **wok**en **disgruntl**ed **co-worke**rs **an**d **borrow**ed **a**n **effecti**ve **wit**h **mil**d **odo**ur. **He**r **foo**d **rea**dy **to**o, **a** **tas**ty **combinati**on **o**f **vitami**ns **minera**ls. **look**ed **u**p **reverent**ly **a**s **que**en **stepp**ed **int**o **he**r **lai**r, **hea**d **hig**h. **coa**t **sparkl**ed **car**e **sil**ky **man**e **fle**w **i**n **bree**ze. **Sh**e **neigh**ed **grateful**ly **delicio**us **sce**nt **fre**sh **gra**ss. **O**n **sun**ny **mornin**gs, **sti**ll **dressi**ng **gow**n, **Edi**th **wou**ld **hobb**le **fro**m **draggi**ng **alo**ng **foldi**ng **cha**ir. **si**t **dow**n **fro**nt **gard**en **wat**ch **peop**le **leavi**ng **wor**k, **childr**en **goi**ng **scho**ol **do**g **walke**rs **headi**ng **par**k. **Anyo**ne **catchi**ng **ey**e **offer**ed **friend**ly **wav**e. **Observi**ng **comin**gs **goin**gs **mad**e **wistf**ul **day**s **whe**n **sh**e **bee**n **bus**y **worki**ng **moth**er. **Th**e **bei**ng **observ**ed **notic**ed **ol**d **wom**an **wish**ed **the**y **cou**ld **tra**de **plac**es, **longi**ng **da**y **the**ir **o**n **weekd**ay **morni**ng, **carefr**ee. **Batter**ed **bruis**ed, **elder**ly **stumbl**ed **no**w **crawli**ng **rea**ch **destinati**on. **bad**ly **beat**en **bu**t **determin**ed. **surviv**or **someh**ow **everyo**ne **kne**w **mak**e **i**t. **Whe**n **arriv**ed **pedest**al, **thru**st **swo**rd **use**d **i**t **suppo**rt **rai**se **herse**lf **standi**ng **positi**on. **withdr**ew **rig**ht **han**d **collect**ed **scal**es **lef**t. **proud**ly **sto**od **tal**l **ere**ct **Lad**y **Justi**ce **final**ly **regain**ed **rightf**ul **Aft**er **arduo**us **tre**k **mor**e **tha**n **tw**o **kilomete**rs **throu**gh **bush**es, **bi**g **boulde**rs, **slippe**ry **slop**es **overnig**ht **rai**n **wel**l **post**ed **Warni**ng **sig**ns **no**t **advan**ce **furth**er, **Ji**m **reach**ed **summ**it **monolith**ic **mounta**in, **hosti**ng **remnan**ts **pas**t **for**t. **Bu**t **las**t **hundr**ed **mete**rs **jagg**ed **sto**ne **hi**m **breathle**ss. **to**p, **beau**ty **natu**re **blu**e **Aege**an **Se**a **dott**ed **volcan**ic **islan**ds **slow-movi**ng **crui**se **shi**ps, **matchi**ng **col**or **cloudle**ss **sk**y **appear**ed **surre**al. **remain**ed **stunn**ed. **The**y **cross**ed **pat**hs **downto**wn **clu**b **198**4. **materi**al **gir**l **shocking-pi**nk **minidre**ss, **neon-yell**ow **pum**ps, **armf**ul **colorf**ul **bangl**es **lock**ed **eye**s **spikey-hair**ed **reb**el **leath**er **pan**ts **mes**h **tan**k, **lov**e **stru**ck. **beca**me **quintessenti**al **eighti**es **coup**le, **you**ng **styli**sh, **futu**re **eve**n **bright**er **cloth**es. **The**se **day**s, **h**e **hid**es **wha**t **i**s **lef**t **hai**r **benea**th **baseba**ll **ha**t **ha**s **trad**ed **fluoresce**nt **froc**ks **wardro**be **neutra**ls, **sometim**es **Frid**ay **nigh**ts **dus**t **of**f **CD**s **dan**ce **unt**il **daw**n. **Be**rkah **sw**ept **t**he **gr**ound **vig**orously. **wa**nted **en**sure **t**hat **eve**rything **w**as **pe**rfect **f**or **h**is **qu**een. **h**ad **st**irred **aw**ake **wo**ndering **dis**infectant **t**oo **st**rong **h**er. **r**un **ma**ster's **ho**use, **wo**ken **dis**gruntled **co-**workers **a**nd **bo**rrowed **ef**fective **w**ith **m**ild **od**our. **H**er **f**ood **re**ady **t**oo, **ta**sty **com**bination **vi**tamins **mi**nerals. **lo**oked **rev**erently **qu**een **st**epped **i**nto **h**er **l**air, **h**ead **h**igh. **c**oat **sp**arkled **c**are **si**lky **m**ane **f**lew **br**eeze. **S**he **ne**ighed **gra**tefully **de**licious **sc**ent **fr**esh **gr**ass. **su**nny **mo**rnings, **st**ill **dr**essing **g**own, **Ed**ith **wo**uld **ho**bble **f**rom **dr**agging **al**ong **fo**lding **ch**air. **s**it **d**own **fr**ont **ga**rden **wa**tch **pe**ople **le**aving **w**ork, **ch**ildren **go**ing **sc**hool **d**og **wa**lkers **he**ading **p**ark. **An**yone **ca**tching **e**ye **of**fered **fr**iendly **w**ave. **Ob**serving **co**mings **go**ings **m**ade **wi**stful **d**ays **w**hen **s**he **b**een **b**usy **wo**rking **mo**ther. **T**he **be**ing **ob**served **no**ticed **o**ld **wo**man **wi**shed **t**hey **co**uld **tr**ade **pl**aces, **lo**nging **d**ay **th**eir **we**ekday **mo**rning, **ca**refree. **Ba**ttered **br**uised, **el**derly **st**umbled **n**ow **cr**awling **re**ach **des**tination. **ba**dly **be**aten **b**ut **det**ermined. **su**rvivor **so**mehow **ev**eryone **k**new **m**ake **W**hen **ar**rived **pe**destal, **th**rust **sw**ord **u**sed **su**pport **ra**ise **he**rself **st**anding **po**sition. **wi**thdrew **ri**ght **h**and **co**llected **sc**ales **l**eft. **pr**oudly **st**ood **t**all **er**ect **L**ady **Ju**stice **fi**nally **re**gained **ri**ghtful **Af**ter **ar**duous **t**rek **m**ore **t**han **t**wo **kil**ometers **th**rough **bu**shes, **b**ig **bo**ulders, **sl**ippery **sl**opes **ov**ernight **r**ain **w**ell **po**sted **Wa**rning **si**gns **n**ot **ad**vance **fu**rther, **J**im **re**ached **su**mmit **mon**olithic **mo**untain, **ho**sting **re**mnants **p**ast **f**ort. **B**ut **l**ast **hu**ndred **me**ters **ja**gged **st**one **h**im **bre**athless. **t**op, **be**auty **na**ture **b**lue **Ae**gean **S**ea **do**tted **vo**lcanic **is**lands **slo**w-moving **cr**uise **sh**ips, **ma**tching **co**lor **cl**oudless **s**ky **ap**peared **su**rreal. **re**mained **st**unned. **T**hey **cr**ossed **pa**ths **do**wntown **c**lub **1**984. **ma**terial **g**irl **sho**cking-pink **mi**nidress, **neo**n-yellow **pu**mps, **ar**mful **co**lorful **ba**ngles **lo**cked **e**yes **spi**key-haired **re**bel **le**ather **pa**nts **m**esh **t**ank, **l**ove **st**ruck. **be**came **qui**ntessential **ei**ghties **co**uple, **yo**ung **st**ylish, **fu**ture **e**ven **br**ighter **cl**othes. **Th**ese **d**ays, **hi**des **w**hat **l**eft **h**air **be**neath **ba**seball **h**at **h**as **tr**aded **flu**orescent **fr**ocks **wa**rdrobe **ne**utrals, **so**metimes **Fr**iday **ni**ghts **d**ust **o**ff **C**Ds **da**nce **un**til **d**awn. Berkah swept the ground vigorously. He wanted to ensure that everything was perfect for his queen. had stirred awake at 4, wondering if disinfectant too strong her. run master's house, woken disgruntled co-workers and borrowed an effective with mild odour. Her food ready too, a tasty combination of vitamins minerals. looked up reverently as queen stepped into her lair, head high. coat sparkled care silky mane flew in breeze. She neighed gratefully delicious scent fresh grass. On sunny mornings, still dressing gown, Edith would hobble from dragging along folding chair. sit down front garden watch people leaving work, children going school dog walkers heading park. Anyone catching eye offered friendly wave. Observing comings goings made wistful days when she been busy working mother. The being observed noticed old woman wished they could trade places, longing day their on weekday morning, carefree. Battered bruised, elderly stumbled now crawling reach destination. badly beaten but determined. survivor somehow everyone knew make it. When arrived pedestal, thrust sword used it support raise herself standing position. withdrew right hand collected scales left. proudly stood tall erect Lady Justice finally regained rightful After arduous trek more than two kilometers through bushes, big boulders, slippery slopes overnight rain well posted Warning signs not advance further, Jim reached summit monolithic mountain, hosting remnants past fort. But last hundred meters jagged stone him breathless. top, beauty nature blue Aegean Sea dotted volcanic islands slow-moving cruise ships, matching color cloudless sky appeared surreal. remained stunned. They crossed paths downtown club 1984. material girl shocking-pink minidress, neon-yellow pumps, armful colorful bangles locked eyes spikey-haired rebel leather pants mesh tank, love struck. became quintessential eighties couple, young stylish, future even brighter clothes. These days, he hides what is left hair beneath baseball hat has traded fluorescent frocks wardrobe neutrals, sometimes Friday nights dust off CDs dance until dawn.\n"
     ]
    }
   ],
   "source": [
    "# This is for the displayed words (not the python version)\n",
    "bio_all_stories =  all_hfhs_story + ' ' + all_lfhs_story + ' ' + all_control_story\n",
    "# Find all unique words\n",
    "bio_all_stories = bio_all_stories.split()\n",
    "\n",
    "unique_words = []\n",
    "\n",
    "for word in bio_all_stories:\n",
    "    if word not in unique_words:\n",
    "        unique_words.append(word)\n",
    "        \n",
    "# All words with the different amount of highlights\n",
    "unique_words = \" \".join(unique_words)\n",
    "\n",
    "print(unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Berk**ah **swe**pt **th**e **grou**nd **vigorous**ly. **H**e **want**ed **t**o **ensu**re **tha**t **everythi**ng **wa**s **perfe**ct **fo**r **hi**s **que**en. **ha**d **stirr**ed **awa**ke **a**t **4**, **wonderi**ng **i**f **disinfecta**nt **to**o **stro**ng **he**r. **ru**n **master**s **hou**se, **wok**en **disgruntl**ed **co-worke**rs **an**d **borrow**ed **a**n **effecti**ve **wit**h **mil**d **odo**ur. **He**r **foo**d **rea**dy **to**o, **a** **tas**ty **combinati**on **o**f **vitami**ns **minera**ls. **look**ed **u**p **reverent**ly **a**s **que**en **stepp**ed **int**o **he**r **lai**r, **hea**d **hig**h. **coa**t **sparkl**ed **car**e **sil**ky **man**e **fle**w **i**n **bree**ze. **Sh**e **neigh**ed **grateful**ly **delicio**us **sce**nt **fre**sh **gra**ss. **O**n **sun**ny **mornin**gs, **sti**ll **dressi**ng **gow**n, **Edi**th **wou**ld **hobb**le **fro**m **draggi**ng **alo**ng **foldi**ng **cha**ir. **si**t **dow**n **fro**nt **gard**en **wat**ch **peop**le **leavi**ng **wor**k, **childr**en **goi**ng **scho**ol **do**g **walke**rs **headi**ng **par**k. **Anyo**ne **catchi**ng **ey**e **offer**ed **friend**ly **wav**e. **Observi**ng **comin**gs **goin**gs **mad**e **wistf**ul **day**s **whe**n **sh**e **bee**n **bus**y **worki**ng **moth**er. **Th**e **bei**ng **observ**ed **notic**ed **ol**d **wom**an **wish**ed **the**y **cou**ld **tra**de **plac**es, **longi**ng **da**y **the**ir **o**n **weekd**ay **morni**ng, **carefr**ee. **Batter**ed **bruis**ed, **elder**ly **stumbl**ed **no**w **crawli**ng **rea**ch **destinati**on. **bad**ly **beat**en **bu**t **determin**ed. **surviv**or **someh**ow **everyo**ne **kne**w **mak**e **i**t. **Whe**n **arriv**ed **pedest**al, **thru**st **swo**rd **use**d **i**t **suppo**rt **rai**se **herse**lf **standi**ng **positi**on. **withdr**ew **rig**ht **han**d **collect**ed **scal**es **lef**t. **proud**ly **sto**od **tal**l **ere**ct **Lad**y **Justi**ce **final**ly **regain**ed **rightf**ul **Aft**er **arduo**us **tre**k **mor**e **tha**n **tw**o **kilomete**rs **throu**gh **bush**es, **bi**g **boulde**rs, **slippe**ry **slop**es **overnig**ht **rai**n **wel**l **post**ed **Warni**ng **sig**ns **no**t **advan**ce **furth**er, **Ji**m **reach**ed **summ**it **monolith**ic **mounta**in, **hosti**ng **remnan**ts **pas**t **for**t. **Bu**t **las**t **hundr**ed **mete**rs **jagg**ed **sto**ne **hi**m **breathle**ss. **to**p, **beau**ty **natu**re **blu**e **Aege**an **Se**a **dott**ed **volcan**ic **islan**ds **slow-movi**ng **crui**se **shi**ps, **matchi**ng **col**or **cloudle**ss **sk**y **appear**ed **surre**al. **remain**ed **stunn**ed. **The**y **cross**ed **pat**hs **downto**wn **clu**b **198**4. **materi**al **gir**l **shocking-pi**nk **minidre**ss, **neon-yell**ow **pum**ps, **armf**ul **colorf**ul **bangl**es **lock**ed **eye**s **spikey-hair**ed **reb**el **leath**er **pan**ts **mes**h **tan**k, **lov**e **stru**ck. **beca**me **quintessenti**al **eighti**es **coup**le, **you**ng **styli**sh, **futu**re **eve**n **bright**er **cloth**es. **The**se **day**s, **h**e **hid**es **wha**t **lef**t **hai**r **benea**th **baseba**ll **ha**t **ha**s **trad**ed **fluoresce**nt **froc**ks **wardro**be **neutra**ls, **sometim**es **Frid**ay **nigh**ts **dus**t **of**f **CD**s **dan**ce **unt**il **daw**n. **Be**rkah **sw**ept **t**he **gr**ound **vig**orously. **wa**nted **en**sure **t**hat **eve**rything **w**as **pe**rfect **f**or **h**is **qu**een. **h**ad **st**irred **aw**ake **wo**ndering **dis**infectant **t**oo **st**rong **h**er. **r**un **ma**sters **ho**use, **wo**ken **dis**gruntled **co-**workers **a**nd **bo**rrowed **ef**fective **w**ith **m**ild **od**our. **H**er **f**ood **re**ady **t**oo, **ta**sty **com**bination **vi**tamins **mi**nerals. **lo**oked **rev**erently **qu**een **st**epped **i**nto **h**er **l**air, **h**ead **h**igh. **c**oat **sp**arkled **c**are **si**lky **m**ane **f**lew **br**eeze. **S**he **ne**ighed **gra**tefully **de**licious **sc**ent **fr**esh **gr**ass. **su**nny **mo**rnings, **st**ill **dr**essing **g**own, **Ed**ith **wo**uld **ho**bble **f**rom **dr**agging **al**ong **fo**lding **ch**air. **s**it **d**own **fr**ont **ga**rden **wa**tch **pe**ople **le**aving **w**ork, **ch**ildren **go**ing **sc**hool **d**og **wa**lkers **he**ading **p**ark. **An**yone **ca**tching **e**ye **of**fered **fr**iendly **w**ave. **Ob**serving **co**mings **go**ings **m**ade **wi**stful **d**ays **w**hen **s**he **b**een **b**usy **wo**rking **mo**ther. **T**he **be**ing **ob**served **no**ticed **o**ld **wo**man **wi**shed **t**hey **co**uld **tr**ade **pl**aces, **lo**nging **d**ay **th**eir **we**ekday **mo**rning, **ca**refree. **Ba**ttered **br**uised, **el**derly **st**umbled **n**ow **cr**awling **re**ach **des**tination. **ba**dly **be**aten **b**ut **det**ermined. **su**rvivor **so**mehow **ev**eryone **k**new **m**ake **W**hen **ar**rived **pe**destal, **th**rust **sw**ord **u**sed **su**pport **ra**ise **he**rself **st**anding **po**sition. **wi**thdrew **ri**ght **h**and **co**llected **sc**ales **l**eft. **pr**oudly **st**ood **t**all **er**ect **L**ady **Ju**stice **fi**nally **re**gained **ri**ghtful **Af**ter **ar**duous **t**rek **m**ore **t**han **t**wo **kil**ometers **th**rough **bu**shes, **b**ig **bo**ulders, **sl**ippery **sl**opes **ov**ernight **r**ain **w**ell **po**sted **Wa**rning **si**gns **n**ot **ad**vance **fu**rther, **J**im **re**ached **su**mmit **mon**olithic **mo**untain, **ho**sting **re**mnants **p**ast **f**ort. **B**ut **l**ast **hu**ndred **me**ters **ja**gged **st**one **h**im **bre**athless. **t**op, **be**auty **na**ture **b**lue **Ae**gean **S**ea **do**tted **vo**lcanic **is**lands **slo**w-moving **cr**uise **sh**ips, **ma**tching **co**lor **cl**oudless **s**ky **ap**peared **su**rreal. **re**mained **st**unned. **T**hey **cr**ossed **pa**ths **do**wntown **c**lub **1**984. **ma**terial **g**irl **sho**cking-pink **mi**nidress, **neo**n-yellow **pu**mps, **ar**mful **co**lorful **ba**ngles **lo**cked **e**yes **spi**key-haired **re**bel **le**ather **pa**nts **m**esh **t**ank, **l**ove **st**ruck. **be**came **qui**ntessential **ei**ghties **co**uple, **yo**ung **st**ylish, **fu**ture **e**ven **br**ighter **cl**othes. **Th**ese **d**ays, **hi**des **w**hat **l**eft **h**air **be**neath **ba**seball **h**at **h**as **tr**aded **flu**orescent **fr**ocks **wa**rdrobe **ne**utrals, **so**metimes **Fr**iday **ni**ghts **d**ust **o**ff **C**Ds **da**nce **un**til **d**awn. Berkah swept the ground vigorously. He wanted to ensure that everything was perfect for his queen. had stirred awake at 4, wondering if disinfectant too strong her. run masters house, woken disgruntled co-workers and borrowed an effective with mild odour. Her food ready too, a tasty combination of vitamins minerals. looked up reverently as queen stepped into her lair, head high. coat sparkled care silky mane flew in breeze. She neighed gratefully delicious scent fresh grass. On sunny mornings, still dressing gown, Edith would hobble from dragging along folding chair. sit down front garden watch people leaving work, children going school dog walkers heading park. Anyone catching eye offered friendly wave. Observing comings goings made wistful days when she been busy working mother. The being observed noticed old woman wished they could trade places, longing day their on weekday morning, carefree. Battered bruised, elderly stumbled now crawling reach destination. badly beaten but determined. survivor somehow everyone knew make it. When arrived pedestal, thrust sword used it support raise herself standing position. withdrew right hand collected scales left. proudly stood tall erect Lady Justice finally regained rightful After arduous trek more than two kilometers through bushes, big boulders, slippery slopes overnight rain well posted Warning signs not advance further, Jim reached summit monolithic mountain, hosting remnants past fort. But last hundred meters jagged stone him breathless. top, beauty nature blue Aegean Sea dotted volcanic islands slow-moving cruise ships, matching color cloudless sky appeared surreal. remained stunned. They crossed paths downtown club 1984. material girl shocking-pink minidress, neon-yellow pumps, armful colorful bangles locked eyes spikey-haired rebel leather pants mesh tank, love struck. became quintessential eighties couple, young stylish, future even brighter clothes. These days, he hides what left hair beneath baseball hat has traded fluorescent frocks wardrobe neutrals, sometimes Friday nights dust off CDs dance until dawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['story_1_hfhs.xlsx', 'story_2_lfhs.xlsx', 'story_3_lfls.xlsx', 'story_4_hfls.xlsx', 'story_5_control.xlsx']\n"
     ]
    }
   ],
   "source": [
    "story = [\"story_1\", \"story_2\", \"story_3\", \"story_4\", \"story_5\"]\n",
    "condition = [\"_hfhs.xlsx\", \"_lfhs.xlsx\", \"_lfls.xlsx\", \"_hfls.xlsx\", \"_control.xlsx\"]\n",
    "\n",
    "selected_condition = [\"\", \"\", \"\", \"\", \"\"]\n",
    "\n",
    "for i in range(0, 5):\n",
    "    selected_condition[i] = story[i] + condition[i]\n",
    "    \n",
    "print(selected_condition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
