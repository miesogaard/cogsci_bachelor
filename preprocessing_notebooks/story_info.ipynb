{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/miesogaard/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_1 = \"Berkah swept the ground vigorously. He wanted to ensure that everything was perfect for his queen. He had stirred awake at 4, wondering if the disinfectant was too strong for her. He had run to his master's house, woken his disgruntled co-workers and borrowed an effective disinfectant with mild odour. Her food was ready too, a tasty combination of vitamins and minerals. Berkah looked up reverently as his queen stepped into her lair, her head high. Her coat sparkled with his care and her silky mane flew in the breeze. She neighed gratefully at the delicious scent of fresh grass.\"\n",
    "\n",
    "story_2 = \"On sunny mornings, still in her dressing gown, Edith would hobble from her house, dragging along a folding chair. She would sit down in her front garden and watch people leaving for work, children going to school and dog walkers heading to the park. Anyone catching her eye was offered a friendly wave. Observing comings and goings of people made her wistful for the days when she had been a busy working mother. The people being observed noticed the old woman and wished they could trade places, longing for the day they could sit in their garden on a sunny weekday morning, carefree.\"\n",
    "\n",
    "story_3 = \"Battered and bruised, the elderly woman had stumbled and was now crawling to reach her destination. She had been badly beaten but was determined. She was a survivor and somehow everyone knew she would make it. When she arrived at the pedestal, she thrust her sword in the ground and used it as a support to raise herself to a standing position. She withdrew the sword from the ground with her right hand and collected her scales with her left. She now proudly stood tall and erect as Lady Justice had finally regained her rightful position.\"\n",
    "\n",
    "story_4 = \"After an arduous trek of more than two kilometers through the bushes, big boulders, slippery slopes from overnight rain as well as posted Warning signs not to advance further, Jim finally reached the summit of the monolithic mountain, still hosting the remnants of a past fort. But it was the last hundred meters of crawling on jagged stone that made him breathless. But from the top, the beauty of nature in front made him more breathless. The blue Aegean Sea dotted with volcanic islands and two slow-moving cruise ships, matching the blue color of cloudless sky appeared surreal. He remained stunned.\"\n",
    "\n",
    "story_5 = \"They crossed paths at a downtown club in 1984. When the material girl in the shocking-pink minidress, neon-yellow pumps, and armful of colorful bangles locked eyes with the spikey-haired rebel in the leather pants and mesh tank, love struck. They became the quintessential eighties couple, young and stylish, with a future even brighter than her clothes. These days, he hides what is left of his hair beneath a baseball hat and she has traded in her fluorescent frocks for a wardrobe of neutrals, but sometimes on Friday nights they dust off their old CDs and dance until dawn.\"\n",
    "\n",
    "story_1_text = story_1.split()\n",
    "\n",
    "story_2_text = story_2.split()\n",
    "\n",
    "story_3_text = story_3.split()\n",
    "\n",
    "story_4_text = story_4.split()\n",
    "\n",
    "story_5_text = story_5.split()\n",
    "\n",
    "all_story_elements = [story_1, story_2, story_3, story_4, story_5]\n",
    "story_elements = [story_1_text, story_2_text, story_3_text, story_4_text, story_5_text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of story 1 is: 100\n",
      "Length of story 2 is: 103\n",
      "Length of story 3 is: 96\n",
      "Length of story 4 is: 101\n",
      "Length of story 5 is: 98\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    print(f'Length of story {i+1} is: {len(story_elements[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_1_clean = []\n",
    "letter_word_1 = []\n",
    "\n",
    "for word in story_1_text:\n",
    "    word = word.lower()\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)\n",
    "    letter_word_1.append(len(word))\n",
    "    story_1_clean.append(word)\n",
    "    \n",
    "story_2_clean = []\n",
    "letter_word_2 = []\n",
    "\n",
    "for word in story_2_text:\n",
    "    word = word.lower()\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)\n",
    "    letter_word_2.append(len(word))\n",
    "    story_2_clean.append(word)\n",
    "\n",
    "story_3_clean = []\n",
    "letter_word_3 = []\n",
    "\n",
    "for word in story_3_text:\n",
    "    word = word.lower()\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)\n",
    "    letter_word_3.append(len(word))\n",
    "    story_3_clean.append(word)\n",
    "\n",
    "story_4_clean = []\n",
    "letter_word_4 = []\n",
    "\n",
    "for word in story_4_text:\n",
    "    word = word.lower()\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)\n",
    "    letter_word_4.append(len(word))\n",
    "    story_4_clean.append(word)\n",
    "    \n",
    "story_5_clean = []\n",
    "letter_word_5 = []\n",
    "\n",
    "for word in story_5_text:\n",
    "    word = word.lower()\n",
    "    word = re.sub(r'[^\\w\\s]', '', word)\n",
    "    letter_word_5.append(len(word))\n",
    "    story_5_clean.append(word)\n",
    "\n",
    "clean_story_elements = [story_1_clean, story_2_clean, story_3_clean, story_4_clean, story_5_clean]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter/word for story 1 is: 4.71 \n",
      "\n",
      "Letter/word for story 2 is: 4.58 \n",
      "\n",
      "Letter/word for story 3 is: 4.55 \n",
      "\n",
      "Letter/word for story 4 is: 4.86 \n",
      "\n",
      "Letter/word for story 5 is: 4.76 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Letter/word for story 1 is: {round(np.mean(letter_word_1), 2)} \\n')\n",
    "print(f'Letter/word for story 2 is: {round(np.mean(letter_word_2), 2)} \\n')\n",
    "print(f'Letter/word for story 3 is: {round(np.mean(letter_word_3), 2)} \\n')\n",
    "print(f'Letter/word for story 4 is: {round(np.mean(letter_word_4), 2)} \\n')\n",
    "print(f'Letter/word for story 5 is: {round(np.mean(letter_word_5), 2)} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type_token Ratio for story 1: 72 \n",
      "\n",
      "Type_token Ratio for story 2: 72 \n",
      "\n",
      "Type_token Ratio for story 3: 64 \n",
      "\n",
      "Type_token Ratio for story 4: 78 \n",
      "\n",
      "Type_token Ratio for story 5: 80 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    unique_words = {}\n",
    "    \n",
    "    for word in story_elements[i]:\n",
    "        word = word.lower()\n",
    "        word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        \n",
    "        if word not in unique_words:\n",
    "            unique_words[word] = 1\n",
    "        else:\n",
    "            unique_words[word] += 1\n",
    "            \n",
    "    print(f'Type_token Ratio for story {i+1}: {round(len(unique_words)/len(story_elements[i])*100)} \\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Density for story 1 is 53.0\n",
      "Lexical Density for story 2 is 60.19\n",
      "Lexical Density for story 3 is 46.88\n",
      "Lexical Density for story 4 is 59.41\n",
      "Lexical Density for story 5 is 55.1\n"
     ]
    }
   ],
   "source": [
    "#Lexical density = (number of lexical words/total number of words) * 100\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "for i in range(0, 5):\n",
    "    f_count = 0\n",
    "    l_count = 0\n",
    "    for word in clean_story_elements[i]:\n",
    "        if word not in stops:\n",
    "            l_count += 1\n",
    "            \n",
    "    print(f'Lexical Density for story {i+1} is {round(l_count / len(clean_story_elements[i]) * 100, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-sentence ratio for story 1: 11.11 \n",
      "\n",
      "Word-sentence ratio for story 2: 17.17 \n",
      "\n",
      "Word-sentence ratio for story 3: 13.71 \n",
      "\n",
      "Word-sentence ratio for story 4: 16.83 \n",
      "\n",
      "Word-sentence ratio for story 5: 19.6 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for stories in all_story_elements:\n",
    "    count += 1\n",
    "    sentence_1 = stories.split(\".\")\n",
    "\n",
    "    number_of_words = []\n",
    "\n",
    "    for sen in sentence_1:\n",
    "        sentence_1_words = sen.split()\n",
    "        length_sen = len(sentence_1_words)\n",
    "\n",
    "        number_of_words.append(length_sen)\n",
    "\n",
    "    print(f'Word-sentence ratio for story {count}: {round(np.mean(number_of_words), 2)} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flesch-Kincaid measured through https://charactercalculator.com/flesch-reading-ease/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
